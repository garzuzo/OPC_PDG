{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/garzuzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd #tratamiento de datos\n",
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('spanish')\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos los modelos generados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model=joblib.load('modelo_entrenado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('modelo_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Word 20</th>\n",
       "      <th>Word 21</th>\n",
       "      <th>Word 22</th>\n",
       "      <th>Word 23</th>\n",
       "      <th>Word 24</th>\n",
       "      <th>Word 25</th>\n",
       "      <th>Word 26</th>\n",
       "      <th>Word 27</th>\n",
       "      <th>Word 28</th>\n",
       "      <th>Word 29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>igualdad</td>\n",
       "      <td>amigos</td>\n",
       "      <td>entorno</td>\n",
       "      <td>cuidar</td>\n",
       "      <td>espacios</td>\n",
       "      <td>bienestar</td>\n",
       "      <td>acciones</td>\n",
       "      <td>seguro</td>\n",
       "      <td>construccion</td>\n",
       "      <td>calle</td>\n",
       "      <td>...</td>\n",
       "      <td>territorios</td>\n",
       "      <td>comparto</td>\n",
       "      <td>soledad</td>\n",
       "      <td>alcanzar</td>\n",
       "      <td>relaciones</td>\n",
       "      <td>aportar</td>\n",
       "      <td>salud</td>\n",
       "      <td>diversion</td>\n",
       "      <td>situaciones</td>\n",
       "      <td>participacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>respeto</td>\n",
       "      <td>personas</td>\n",
       "      <td>demas_personas</td>\n",
       "      <td>diferencias</td>\n",
       "      <td>contar</td>\n",
       "      <td>respeto_hacia</td>\n",
       "      <td>tratar</td>\n",
       "      <td>raza</td>\n",
       "      <td>gente</td>\n",
       "      <td>ambiente</td>\n",
       "      <td>...</td>\n",
       "      <td>ser_tolerante</td>\n",
       "      <td>poder_convivir</td>\n",
       "      <td>medio_ambiente</td>\n",
       "      <td>cero</td>\n",
       "      <td>tierra</td>\n",
       "      <td>barrios</td>\n",
       "      <td>hija</td>\n",
       "      <td>corrupcion</td>\n",
       "      <td>ciudadano</td>\n",
       "      <td>hallar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>tranquilo</td>\n",
       "      <td>sociedad</td>\n",
       "      <td>no_violencia</td>\n",
       "      <td>vida</td>\n",
       "      <td>mejor</td>\n",
       "      <td>educacion</td>\n",
       "      <td>oportunidades</td>\n",
       "      <td>social</td>\n",
       "      <td>saber</td>\n",
       "      <td>siempre</td>\n",
       "      <td>...</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>conocer</td>\n",
       "      <td>dejar</td>\n",
       "      <td>ausencia</td>\n",
       "      <td>diferencia</td>\n",
       "      <td>aceptacion</td>\n",
       "      <td>sentirme</td>\n",
       "      <td>siento</td>\n",
       "      <td>convivencia</td>\n",
       "      <td>no_discriminacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>armonia</td>\n",
       "      <td>felicidad</td>\n",
       "      <td>generar</td>\n",
       "      <td>hijos</td>\n",
       "      <td>corazon</td>\n",
       "      <td>vida</td>\n",
       "      <td>sana_convivencia</td>\n",
       "      <td>alegria</td>\n",
       "      <td>ser_humano</td>\n",
       "      <td>barrio</td>\n",
       "      <td>...</td>\n",
       "      <td>transmitir</td>\n",
       "      <td>dar</td>\n",
       "      <td>reflejo</td>\n",
       "      <td>familias</td>\n",
       "      <td>unir</td>\n",
       "      <td>brindar</td>\n",
       "      <td>encontrar</td>\n",
       "      <td>considerar</td>\n",
       "      <td>poder_compartir</td>\n",
       "      <td>futuro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>tranquilidad</td>\n",
       "      <td>respeto</td>\n",
       "      <td>solidaridad</td>\n",
       "      <td>confianza</td>\n",
       "      <td>personal</td>\n",
       "      <td>tolerancia</td>\n",
       "      <td>reflejar</td>\n",
       "      <td>valores</td>\n",
       "      <td>hogar</td>\n",
       "      <td>dialogo</td>\n",
       "      <td>...</td>\n",
       "      <td>bien</td>\n",
       "      <td>educacion</td>\n",
       "      <td>permitir</td>\n",
       "      <td>caminar</td>\n",
       "      <td>comunitario</td>\n",
       "      <td>equidad</td>\n",
       "      <td>diferencia</td>\n",
       "      <td>diversidad</td>\n",
       "      <td>economica</td>\n",
       "      <td>derechos_sociales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>construir</td>\n",
       "      <td>mundo</td>\n",
       "      <td>libertad</td>\n",
       "      <td>respeto</td>\n",
       "      <td>armonia</td>\n",
       "      <td>lograr</td>\n",
       "      <td>perdonar</td>\n",
       "      <td>bueno</td>\n",
       "      <td>derechos</td>\n",
       "      <td>territorio</td>\n",
       "      <td>...</td>\n",
       "      <td>deporte</td>\n",
       "      <td>aceptar</td>\n",
       "      <td>ayudar</td>\n",
       "      <td>cumplir</td>\n",
       "      <td>partir</td>\n",
       "      <td>practicar</td>\n",
       "      <td>necesario</td>\n",
       "      <td>fundamental</td>\n",
       "      <td>capacidad</td>\n",
       "      <td>cultura_ciudadana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>amor</td>\n",
       "      <td>respeto</td>\n",
       "      <td>tolerancia</td>\n",
       "      <td>pensar</td>\n",
       "      <td>conflictos</td>\n",
       "      <td>personas</td>\n",
       "      <td>seguridad</td>\n",
       "      <td>diferente</td>\n",
       "      <td>persona</td>\n",
       "      <td>respeto_tolerancia</td>\n",
       "      <td>...</td>\n",
       "      <td>mas_importante</td>\n",
       "      <td>aceptar</td>\n",
       "      <td>pueblo</td>\n",
       "      <td>convivir</td>\n",
       "      <td>mediar</td>\n",
       "      <td>alrededor</td>\n",
       "      <td>positivo</td>\n",
       "      <td>importante</td>\n",
       "      <td>social</td>\n",
       "      <td>servir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>dios</td>\n",
       "      <td>solo</td>\n",
       "      <td>entender</td>\n",
       "      <td>existir</td>\n",
       "      <td>musica</td>\n",
       "      <td>disfrutar</td>\n",
       "      <td>escuchar</td>\n",
       "      <td>projimo</td>\n",
       "      <td>conflicto</td>\n",
       "      <td>encuentro</td>\n",
       "      <td>...</td>\n",
       "      <td>situacion</td>\n",
       "      <td>comprender</td>\n",
       "      <td>amistad</td>\n",
       "      <td>hablar</td>\n",
       "      <td>expresar</td>\n",
       "      <td>serenidad</td>\n",
       "      <td>darle</td>\n",
       "      <td>comer</td>\n",
       "      <td>gustar</td>\n",
       "      <td>madre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>naturaleza</td>\n",
       "      <td>casa</td>\n",
       "      <td>sentir</td>\n",
       "      <td>convivencia</td>\n",
       "      <td>problemas</td>\n",
       "      <td>representar</td>\n",
       "      <td>llegar</td>\n",
       "      <td>conciencia</td>\n",
       "      <td>forma</td>\n",
       "      <td>tener_buena</td>\n",
       "      <td>...</td>\n",
       "      <td>animales</td>\n",
       "      <td>llego</td>\n",
       "      <td>parque</td>\n",
       "      <td>paloma</td>\n",
       "      <td>seres_queridos</td>\n",
       "      <td>significar</td>\n",
       "      <td>valores</td>\n",
       "      <td>caminar</td>\n",
       "      <td>honestidad</td>\n",
       "      <td>contaminacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>familia</td>\n",
       "      <td>vivir</td>\n",
       "      <td>comunidad</td>\n",
       "      <td>personas</td>\n",
       "      <td>armonia</td>\n",
       "      <td>compartir</td>\n",
       "      <td>bien</td>\n",
       "      <td>interior</td>\n",
       "      <td>union</td>\n",
       "      <td>bueno</td>\n",
       "      <td>...</td>\n",
       "      <td>crecer</td>\n",
       "      <td>serio</td>\n",
       "      <td>perdon</td>\n",
       "      <td>tipo</td>\n",
       "      <td>familiar</td>\n",
       "      <td>entendimiento</td>\n",
       "      <td>armas</td>\n",
       "      <td>dibujar</td>\n",
       "      <td>ninos</td>\n",
       "      <td>problema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word 0     Word 1          Word 2       Word 3      Word 4  \\\n",
       "Topic 0      igualdad     amigos         entorno       cuidar    espacios   \n",
       "Topic 1       respeto   personas  demas_personas  diferencias      contar   \n",
       "Topic 2     tranquilo   sociedad    no_violencia         vida       mejor   \n",
       "Topic 3       armonia  felicidad         generar        hijos     corazon   \n",
       "Topic 4  tranquilidad    respeto     solidaridad    confianza    personal   \n",
       "Topic 5     construir      mundo        libertad      respeto     armonia   \n",
       "Topic 6          amor    respeto      tolerancia       pensar  conflictos   \n",
       "Topic 7          dios       solo        entender      existir      musica   \n",
       "Topic 8    naturaleza       casa          sentir  convivencia   problemas   \n",
       "Topic 9       familia      vivir       comunidad     personas     armonia   \n",
       "\n",
       "                Word 5            Word 6      Word 7        Word 8  \\\n",
       "Topic 0      bienestar          acciones      seguro  construccion   \n",
       "Topic 1  respeto_hacia            tratar        raza         gente   \n",
       "Topic 2      educacion     oportunidades      social         saber   \n",
       "Topic 3           vida  sana_convivencia     alegria    ser_humano   \n",
       "Topic 4     tolerancia          reflejar     valores         hogar   \n",
       "Topic 5         lograr          perdonar       bueno      derechos   \n",
       "Topic 6       personas         seguridad   diferente       persona   \n",
       "Topic 7      disfrutar          escuchar     projimo     conflicto   \n",
       "Topic 8    representar            llegar  conciencia         forma   \n",
       "Topic 9      compartir              bien    interior         union   \n",
       "\n",
       "                     Word 9  ...         Word 20         Word 21  \\\n",
       "Topic 0               calle  ...     territorios        comparto   \n",
       "Topic 1            ambiente  ...   ser_tolerante  poder_convivir   \n",
       "Topic 2             siempre  ...       necesitar         conocer   \n",
       "Topic 3              barrio  ...      transmitir             dar   \n",
       "Topic 4             dialogo  ...            bien       educacion   \n",
       "Topic 5          territorio  ...         deporte         aceptar   \n",
       "Topic 6  respeto_tolerancia  ...  mas_importante         aceptar   \n",
       "Topic 7           encuentro  ...       situacion      comprender   \n",
       "Topic 8         tener_buena  ...        animales           llego   \n",
       "Topic 9               bueno  ...          crecer           serio   \n",
       "\n",
       "                Word 22   Word 23         Word 24        Word 25     Word 26  \\\n",
       "Topic 0         soledad  alcanzar      relaciones        aportar       salud   \n",
       "Topic 1  medio_ambiente      cero          tierra        barrios        hija   \n",
       "Topic 2           dejar  ausencia      diferencia     aceptacion    sentirme   \n",
       "Topic 3         reflejo  familias            unir        brindar   encontrar   \n",
       "Topic 4        permitir   caminar     comunitario        equidad  diferencia   \n",
       "Topic 5          ayudar   cumplir          partir      practicar   necesario   \n",
       "Topic 6          pueblo  convivir          mediar      alrededor    positivo   \n",
       "Topic 7         amistad    hablar        expresar      serenidad       darle   \n",
       "Topic 8          parque    paloma  seres_queridos     significar     valores   \n",
       "Topic 9          perdon      tipo        familiar  entendimiento       armas   \n",
       "\n",
       "             Word 27          Word 28            Word 29  \n",
       "Topic 0    diversion      situaciones      participacion  \n",
       "Topic 1   corrupcion        ciudadano             hallar  \n",
       "Topic 2       siento      convivencia  no_discriminacion  \n",
       "Topic 3   considerar  poder_compartir             futuro  \n",
       "Topic 4   diversidad        economica  derechos_sociales  \n",
       "Topic 5  fundamental        capacidad  cultura_ciudadana  \n",
       "Topic 6   importante           social             servir  \n",
       "Topic 7        comer           gustar              madre  \n",
       "Topic 8      caminar       honestidad      contaminacion  \n",
       "Topic 9      dibujar            ninos           problema  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=30)        \n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de un nuevo texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluaremos un nuevo texto, pero antes tenemos que hacer una respectiva limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text= \"Para mi la paz es tener tranquilidad en mi hogar con mi familia, mis amigas y mi perro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text= re.sub('[,\\.\\'\\\"!\\)(?0-9]', '', text).lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc= True))  # deacc=True removes punctuations\n",
    "\n",
    "data = [text]\n",
    "data_tokenized = list(sent_to_words(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words_exceptions=[\"no\"]\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if (word not in stop_words) or (word in stop_words_exceptions)] for doc in texts]\n",
    "    \n",
    "    \n",
    "data_tokenized_nostops= remove_stopwords(data_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_tokenized, min_count=7, threshold=5) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_tokenized], threshold=5)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "data_bigrams_nonstops=make_bigrams(data_tokenized_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['paz', 'tener', 'tranquilidad', 'hogar', 'familia', 'amigas', 'perro']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bigrams_nonstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tener tranquilidad hogar familia amigas perro']\n"
     ]
    }
   ],
   "source": [
    "data = data_bigrams_nonstops\n",
    "\n",
    "data_prepared=[]\n",
    "for row in data:\n",
    "    text=\"\"\n",
    "    for word in row:\n",
    "        if(len(word) > 3):\n",
    "            text+=word + \" \"\n",
    "    data_prepared.append(text.rstrip())\n",
    "\n",
    "print(data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_postags=['ADJ', 'VERB', 'ADV']\n",
    "stopwordsToken=[\"demas\",\"tener\",\"mismo\", \"poder\",\"cada\",\"tambien\", \"hacer\"]\n",
    "unifiedWord={\"respetar\":\"respeto\", \"violencia\":\"no_violencia\",\"musicar\":\"musica\",\"guerra\":\"no_guerra\"}\n",
    "data_list=[]\n",
    "\n",
    "token_list=\"\"\n",
    "text=nlp(data_prepared[0])\n",
    "for token in text:\n",
    "    if (token.pos_ in allowed_postags) and (token.lemma_ not in stopwordsToken) and (token.text not in stopwordsToken):\n",
    "        if token.lemma_ in unifiedWord:\n",
    "            token_list+=unifiedWord[token.lemma_]+\" \"\n",
    "        else :\n",
    "            token_list+=token.lemma_+\" \"\n",
    "\n",
    "    elif (token.is_stop is not True) and (token.lemma_ not in stopwordsToken) and (token.text not in stopwordsToken):\n",
    "        if token.text in unifiedWord:\n",
    "            token_list+=unifiedWord[token.text]+\" \"\n",
    "        else :\n",
    "            token_list+=token.text+\" \"\n",
    "data_list.append(token_list.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tranquilidad hogar familia amigas perro']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora transformamos el texto procesado en una matriz de dispersión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 181)\t1\n",
      "  (0, 214)\t1\n",
      "  (0, 426)\t1\n"
     ]
    }
   ],
   "source": [
    "text_processed=vectorizer.transform(data_list)\n",
    "print(text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_probability_scores = lda_model.transform(text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0250002  0.025      0.02500212 0.02500561 0.51681747 0.025\n",
      "  0.02500464 0.025      0.02500153 0.28316842]]\n"
     ]
    }
   ],
   "source": [
    "print(topic_probability_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(topic_probability_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic = df_topic_keywords.iloc[np.argmax(topic_probability_scores), :].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranquilidad, respeto, solidaridad, confianza, personal, tolerancia, reflejar, valores, hogar, dialogo, construccion, unidad, medio_ambiente, adultos, generar, comun, interpersonal, practicar, normas, seres_humanos, bien, educacion, permitir, caminar, comunitario, equidad, diferencia, diversidad, economica, derechos_sociales\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(topic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
